// @HEAD_COMMENT@
// Author: Federico Sossai (fsossai), 2021

#include <benchmark/benchmark.h>
//#include <onnxruntime/core/session/onnxruntime_cxx_api.h>
#include <onnxruntime_cxx_api.h>

#include <iostream>
#include <vector>
#include <numeric>
#include <random>
#include <chrono>

using namespace std;

static void @FUNC_NAME@(benchmark::State& state, string model_path)
{
   Ort::Env env(ORT_LOGGING_LEVEL_WARNING, "benchmark");
   
   Ort::SessionOptions session_options;
   session_options.SetIntraOpNumThreads(1);
   session_options.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_EXTENDED);

   //std::cout << "benchmarking model " << model_path << std::endl;
   Ort::Session session(env, model_path.c_str(), session_options);

   vector<const char*> input_node_names(1);
   vector<const char*> output_node_names(1);
   
   Ort::AllocatorWithDefaultOptions allocator;
   input_node_names[0] = session.GetInputName(0, allocator);
   output_node_names[0] = session.GetOutputName(0, allocator);

   // Getting the shapes

   vector<int64_t> input_node_dims = session
      .GetInputTypeInfo(0).GetTensorTypeAndShapeInfo().GetShape();
   vector<int64_t> output_node_dims = session
      .GetOutputTypeInfo(0).GetTensorTypeAndShapeInfo().GetShape();

   // Calculating the dimension of the input tensor
   int nevts = 64;
   int bsize = input_node_dims[0];
   //std::cout << "Using bsize = " << bsize << std::endl;
   int nbatches = nevts / bsize;

   size_t input_tensor_size = accumulate(input_node_dims.begin(),
      input_node_dims.end(), 1, multiplies<int>());
   vector<float> input_tensor_values(input_tensor_size*nbatches);

   // Input tensor initialization   
   static std::uniform_real_distribution<float> distribution(-1,1);
   static std::default_random_engine generator;
   std::generate(input_tensor_values.begin(), input_tensor_values.end(), []() { return distribution(generator); });
   //fill_n(input_tensor_values.begin(), input_tensor_size, 1.0);

   auto memory_info = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);
   Ort::Value input_tensor = Ort::Value::CreateTensor<float>(memory_info,
      input_tensor_values.data(), input_tensor_size,
      input_node_dims.data(), input_node_dims.size());

   // Running the model
   float * floatarr = nullptr;

   double totDuration = 0;
   int ntimes = 0;
   for (auto _ : state) {
      auto t1 = std::chrono::high_resolution_clock::now();
      for (int i = 0; i < nevts; i+= bsize) {
         auto output_tensors = session.Run(Ort::RunOptions{nullptr}, input_node_names.data(), &input_tensor, 1,
                                           output_node_names.data(), 1);
         floatarr = output_tensors.front().GetTensorMutableData<float>();
      }

      auto t2 = std::chrono::high_resolution_clock::now();
      auto duration = std::chrono::duration_cast<std::chrono::microseconds>(t2 - t1).count();
      totDuration += duration / 1.E3; // in milliseconds
      ntimes++;
   }
   //for (int i = 0; i < 10; i++)
   //  printf("%f\t", i, floatarr[i]);
   state.counters["time/evt(ms)"] = totDuration / double(ntimes * nevts);

}
@BENCHMARK_CAPTURES@

BENCHMARK_MAIN();